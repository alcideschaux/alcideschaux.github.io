<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alcides Chaux">

<title>ChauxLab - 3 principios éticos claves para la implementación de la inteligencia artificial</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-WRPMWGFZ6G"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-WRPMWGFZ6G', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script> 
  


<link rel="stylesheet" href="../../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">ChauxLab</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Buscar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Navegación de palanca" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../index.html" rel="" target="">
 <span class="menu-text">Inicio</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../asesoria.html" rel="" target="">
 <span class="menu-text">Asesoría</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../about.html" rel="" target="">
 <span class="menu-text">Acerca de</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/alcideschaux/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/alcideschaux/" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/alcideschaux/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">En esta página</h2>
   
  <ul>
  <li><a href="#equidad" id="toc-equidad" class="nav-link active" data-scroll-target="#equidad">Equidad</a></li>
  <li><a href="#responsabilidad" id="toc-responsabilidad" class="nav-link" data-scroll-target="#responsabilidad">Responsabilidad</a></li>
  <li><a href="#transparencia" id="toc-transparencia" class="nav-link" data-scroll-target="#transparencia">Transparencia</a></li>
  <li><a href="#conclusión" id="toc-conclusión" class="nav-link" data-scroll-target="#conclusión">Conclusión</a></li>
  <li><a href="#enlaces-de-interés" id="toc-enlaces-de-interés" class="nav-link" data-scroll-target="#enlaces-de-interés">Enlaces de interés</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">3 principios éticos claves para la implementación de la inteligencia artificial</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Inteligencia Artificial</div>
    <div class="quarto-category">Innovación</div>
    <div class="quarto-category">Ética</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Autor/a</div>
    <div class="quarto-title-meta-contents">
             <p>Alcides Chaux </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Fecha de publicación</div>
    <div class="quarto-title-meta-contents">
      <p class="date">21 de enero de 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><img src="2024-01-21.jpg" class="img-fluid"></p>
<hr>
<p>Es indudable que la inteligencia artificial (IA) está teniendo un impacto cada vez mayor en nuestras vidas.</p>
<p>Desde asistentes virtuales hasta vehículos autónomos, la IA está remodelando la sociedad de formas que eran inimaginables hace apenas unos años. En mi campo de investigación y especialidad, el uso de la IA para el diagnóstico y clasificación de tumores se extiende cada vez más.</p>
<p>Son tiempos de mucho entusiasmo y expectativas. La IA tiene el potencial de transformar no solo la forma en la que hacemos ciencia, sino nuestra visión misma de la realidad. Sin embargo, a medida que esta tecnología se vuelve más sofisticada y omnipresente, surgen preguntas éticas urgentes sobre cómo debemos diseñar, implementar y regular los sistemas de IA.</p>
<p>Filosofías y movimientos sociales como el altruismo efectivo han expresado su preocupación sobre el impacto de la IA en el futuro de la humanidad, especialmente el riesgo de que surja una IA superinteligente que pueda causar daños irreversibles o incluso la extinción de nuestra especie. Personalmente, no es una de mis corrientes filosóficas favoritas, pero indudablemente sus argumentos tienen mérito.</p>
<p>Este es un tema que he debatido también extensamente con colegas. Y llegar a puntos de acuerdo puede ser complicado, sobre todo cuando se parten de posiciones filosóficas y antropológicas divergentes. A pesar de lo complicada y polarizada que puede llegar a ser este tipo de discusiones, son conversaciones que debemos tener.</p>
<p>Mi posición con respecto a la inteligencia artificial es clara — no creo que presente un riesgo existencial significativo. Encuentro esos escenarios apocalípticos y distópicos en los que la AI toma el control y destruye a la humanidad, simplemente absurdos. Pero esto es tema para otra entrada.</p>
<p>Volviendo al tópico a mano, recientemente, he tomado en DataCamp un excelente <a href="https://app.datacamp.com/learn/courses/ai-ethics">curso sobre IA y ética</a> de Joe Franklin, quien ha propuesto 3 principios éticos clave a tener en cuenta: equidad, responsabilidad y transparencia. En esta entrada, te contaré acerca de estos principios y el porqué creo que adoptarlos será esencial para garantizar que maximizamos los beneficios de la IA, mientras minimizamos los daños potenciales.</p>
<section id="equidad" class="level1">
<h1>Equidad</h1>
<p>El principio de equidad establece que los sistemas de IA deben beneficiar a todas las personas por igual, sin discriminar o favorecer ciertos grupos sobre otros. La IA tiene el potencial de exacerbar las desigualdades sociales si sesga los resultados en contra de grupos desfavorecidos. Esto tiene mucho que ver con la forma en la que se entrenan los algoritmos de IA.</p>
<p>Por ejemplo, existe evidencia de que los algoritmos utilizados en contratación y préstamos discriminan contra solicitantes de minorías, incluso cuando afirman ser objetivos. Esto no es algo que inherentemente esté «mal» en la IA — son sesgos que ha aprendido debido a que nosotros mismos, como humanos y como sociedad, tenemos estos sesgos.</p>
<p>Si no se abordan estos sesgos, la IA podría negar oportunidades vitales a millones de personas. Para cumplir con el principio de equidad, los sistemas de IA deben diseñarse intencionalmente para promover la inclusión. Los conjuntos de datos utilizados para entrenarlos también deben ser representativos de diversas poblaciones.</p>
<p>Debemos, por lo tanto, asumir y reconocer los sesgos que nosotros mismos tenemos, y buscar formas efectivas de minimizarlos al implementar soluciones y estrategias de IA.</p>
<p>Solo entonces la IA podrá beneficiar a toda la humanidad. Cuando nosotros como humanos asumamos también nuestra humanidad en común.</p>
</section>
<section id="responsabilidad" class="level1">
<h1>Responsabilidad</h1>
<p>El principio de responsabilidad establece que debe haber supervisión y control humano significativo sobre los sistemas de IA. También debe haber mecanismos para determinar quién es responsable cuando las cosas van mal con la IA.</p>
<p>Por ejemplo, si un vehículo autónomo tiene un accidente fatal, ¿es la empresa fabricante la responsable y, por tanto, plausible de ser demandada? Del mismo modo, un médico debe supervisar cualquier diagnóstico o tratamiento recomendado por la IA y asumir la responsabilidad final por el bienestar del paciente.</p>
<p>Esto es algo que debe dejarse claro y con el menor grado de ambigüedad posible. Uno de los tantos conceptos que aprendí del excelente curso del Dr.&nbsp;Jules White en Coursera sobre <a href="https://www.coursera.org/learn/prompt-engineering">Prompt Engineering for ChatGPT</a> se relaciona justamente con este aspecto. Debemos «adueñarnos» de sea lo que decidamos hacer con lo que obtengamos de la IA.</p>
<p>En mi caso, frecuentemente uso la IA para mis análisis de datos. Esto no significa que, si como consecuencia de este análisis, se produce algún daño o desenlace desafortunado, yo soy menos responsable. La IA puede sugerirme un fragmento de código en Python para poner a prueba alguna idea de investigación, pero soy yo quien decido implementar ese código. Usar IA sin tener una pericia de dominio, un conocimiento específico del campo de aplicación, es muy peligroso.</p>
<p>La IA por sí sola no es una entidad moral. Por lo tanto, se debe mantener bajo control humano. Sin líneas claras de responsabilidad, la IA podría violar derechos y causar daños sin consecuencias.</p>
<p>Y esto es aplicable más allá del uso personal o profesional que uno pueda hacer de la IA. Las empresas que implementan soluciones de IA también deben someterse a auditorías externas para verificar su seguridad. Solamente mediante la rendición de cuentas, la IA ganará la confianza del público.</p>
</section>
<section id="transparencia" class="level1">
<h1>Transparencia</h1>
<p>La transparencia en la implementación de la IA es un principio esencial que asegura que los sistemas de IA no solo sean eficientes, sino también comprensibles y accesibles para los usuarios. La transparencia implica que los sistemas de IA deben ser explicables — en otras palabras, no deben operar como «cajas negras» incomprensibles. Una caja negra se refiere a un algoritmo que, a pesar de su capacidad para predecir resultados, resulta indescifrable desde una perspectiva humana.</p>
<p>Es crucial que los algoritmos y modelos de IA sean capaces de comunicar, de manera clara y en un lenguaje accesible, cómo llegaron a una determinada conclusión o recomendación. Por ejemplo, si un sistema de IA rechaza una solicitud de préstamo o sugiere un tratamiento médico específico, es esencial que el proceso detrás de estas decisiones sea transparente y comprensible para quienes tomarán acciones basadas en estas recomendaciones.</p>
<p>Esto es algo que, para mi función como científico de datos, es vital. Por ello, cada modelo predictivo o pronóstico que desarrollo, cada conclusión a la que llego, debe ser comprensible para los otros miembros del equipo de investigación. Si no puedo mostrar y explicar cómo llegué a un resultado en particular, en términos que sean comprensibles para todos, es un signo de que debo mejorar el enfoque usado.</p>
<p>Este concepto de transparencia se vincula estrechamente con la responsabilidad. No es posible asumir responsabilidad por algo que no se comprende. Por ello, la transparencia en los algoritmos de IA es fundamental para entender los procesos que conducen a ciertas conclusiones o resultados. Esto permite a los usuarios y responsables «adueñarse» de esas decisiones y asumir responsabilidad por las acciones derivadas de dicha información.</p>
<p>Además, la transparencia en los sistemas de IA contribuye a su confiabilidad. Permite a los usuarios validar la corrección de las recomendaciones, asegurándose de que no existan sesgos discriminatorios o errores.</p>
<p>Es importante destacar que la transparencia no debe ser una consideración posterior al desarrollo del algoritmo. Debe ser un componente integral desde el inicio del diseño de sistemas de IA, manteniendo siempre en mente la necesidad de explicabilidad y comprensión. La incorporación de la transparencia desde las etapas iniciales del diseño garantiza que los sistemas de IA sean no solo técnicamente avanzados, sino también éticamente responsables y socialmente aceptables.</p>
</section>
<section id="conclusión" class="level1">
<h1>Conclusión</h1>
<p>La inteligencia artificial tiene el potencial de mejorar drásticamente la sociedad, pero también plantea riesgos de daño si se desarrolla y utiliza de manera irresponsable. Adoptar principios bioéticos de equidad, responsabilidad y transparencia será esencial para guiar la IA hacia beneficios ampliamente compartidos. Esta no es una lista exhaustiva, y es evidente que existen otros principios que debemos tener en cuenta, tales como los relacionados con la privacidad y la seguridad de los datos.</p>
<p>Es crucial identificar adecuadamente estos principios. Discutirlos. Implementarlos como salvaguardas. Es la única manera de diseñar intencionalmente la IA para promover la inclusión, la rendición de cuentas y la explicabilidad desde el principio.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Te invito a reflexionar sobre estos puntos. Únete a mi servidor de <a href="https://discord.gg/hygGSHrX">Discord</a> y continuemos la conversación sobre cómo podemos hacer para imbuir estos principios en el desarrollo y uso de sistemas de IA. Comparte tus experiencias, dudas e inquietudes al respecto.</p>
</div>
</div>
</section>
<section id="enlaces-de-interés" class="level1">
<h1>Enlaces de interés</h1>
<ul>
<li><a href="https://www.ibm.com/es-es/topics/ai-ethics">¿Qué es la ética de la IA?</a></li>
<li><a href="https://www.unesco.org/es/legal-affairs/recommendation-ethics-artificial-intelligence">Recomendaciones de la UNESCO sobre la ética de la inteligencia artificial</a></li>
</ul>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Volver arriba</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">Alcides Chaux, M.D., 2023-2024 – Licencia <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.es">CC BY-NC-ND 4.0</a><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>